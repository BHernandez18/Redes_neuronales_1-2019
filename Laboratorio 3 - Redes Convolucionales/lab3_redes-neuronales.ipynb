{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "domingo 16 de mayo de 2019  \n",
    "  \n",
    "_Benjamín Hernández Cortés_ - _Juan Pablo Rojas Rojas_  \n",
    "_Departamento de Ingeniería Informática (DIINF)_  \n",
    "_Universidad de Santiago de Chile (USACH)_\n",
    "\n",
    "\n",
    "## Laboratorio 3 - Fundamentos de Aprendizaje Profundo con Redes Neuronales\n",
    "___\n",
    "\n",
    "El presente código está orientado hacia la implementación de una red neuronal convolucional o CNN (Convolutional Neural Network), la cual será diseñada y empleada con el fin de clasificar un conjunto de 25.000 imagenes de perros y gatos, que pueden ser descargados a través del siguiente enlace: [Kaggle Cats and Dogs Dataset](https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765).\n",
    "\n",
    "\n",
    "#### Importación de bibliotecas\n",
    "---\n",
    "\n",
    "Las bibliotecas a emplear son:\n",
    "- **os:** Manejo de funcionalidades dependientes del sistema operativo\n",
    "- **numpy:** Herramienta de computación científica, que permite trabajar a través de vectores\n",
    "- **matplotlib:** Visualización gráfica de diversos datos de interés\n",
    "- **tensorflow:** Diseño e implementación de la red neuronal convolucional\n",
    "- **cv2:** Manejo del conjunto de imagenes\n",
    "- **random:** Uso de funciones relacionadas con la aleatoriedad\n",
    "- **tqdm:** Barra de progreso interactiva\n",
    "\n",
    "#### ¡Precauciones!\n",
    "---\n",
    "\n",
    "Para asegurar el correcto funcionamiento de la herramienta, es necesario tener en cuenta las siguientes precauciones y las acciones a tomar, para el reparar algunas funcionalidades que podrían presentar problemas.\n",
    "\n",
    "| <p style='text-align: left;'>**Error**</p>  | <p style='text-align: left;'>**Descripción**</p> |\n",
    "| ------------ | ------------ |\n",
    "| <p style='text-align: justify;'>`UnboundLocalError: local variable 'photoshop' referenced before assignment`</p> |  <p style='text-align: justify;'>Este mensaje de error se presenta al momento de utilizar la clase _ImageDataGenerator_ de _tensorflow.keras.preprocessing.image_. Este error puede ser reparado haciendo una leve modificación al archivo _JpegImagePlugin.py_ asociado a la biblioteca _PIL_, siguiendo los pasos indicados en este [post](https://github.com/python-pillow/Pillow/pull/3771#issuecomment-485104596).</p>|\n",
    "| <p style='text-align: justify;'>`Problema al obtener/cargar las imagenes`</p> |  <p style='text-align: justify;'>El conjunto de imagenes indicado al principio de este trabajo ([Kaggle Cats and Dogs Dataset](https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765)), posee un par de imagenes que no contienen información y por lo tanto, no pueden ser empleados. Las imagenes en cuestión son _/PetImages/Cat/666.jpg_ y _/PetImages/Dog/11702.jpg_. Se recomienda que elimine las imagenes anteriormente indicadas, previo a la ejecución de este archivo.</p>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17500 images belonging to 2 classes.\n",
      "Found 7498 images belonging to 2 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 56, 56, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 315,010\n",
      "Trainable params: 315,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "75/75 [==============================] - 63s 839ms/step - loss: 0.6187 - acc: 0.6570\n",
      "175/175 [==============================] - 236s 1s/step - loss: 0.6565 - acc: 0.6035 - val_loss: 0.6187 - val_acc: 0.6570\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 62s 831ms/step - loss: 0.5368 - acc: 0.7253\n",
      "175/175 [==============================] - 229s 1s/step - loss: 0.5663 - acc: 0.7090 - val_loss: 0.5368 - val_acc: 0.7253\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 62s 831ms/step - loss: 0.4861 - acc: 0.7682\n",
      "175/175 [==============================] - 229s 1s/step - loss: 0.4995 - acc: 0.7576 - val_loss: 0.4861 - val_acc: 0.7682\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 62s 832ms/step - loss: 0.4744 - acc: 0.7707\n",
      "175/175 [==============================] - 229s 1s/step - loss: 0.4539 - acc: 0.7840 - val_loss: 0.4744 - val_acc: 0.7707\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 63s 839ms/step - loss: 0.4909 - acc: 0.7631\n",
      "175/175 [==============================] - 230s 1s/step - loss: 0.4181 - acc: 0.8073 - val_loss: 0.4909 - val_acc: 0.7631\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 60\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
    "BATCH_SIZE = 32\n",
    "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 1)\n",
    "DIR = \"C:\\\\Users\\\\Familia Hernández\\\\Desktop\\\\Redes_neuronales_1-2019\\\\Laboratorio 3 - Redes Convolucionales\\\\PetImages\\\\Cat\"\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                             validation_split=0.3)\n",
    "\n",
    "# Conjunto de prueba\n",
    "training_dataset = datagen.flow_from_directory('PetImages/',\n",
    "                                               target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                               batch_size=100,\n",
    "                                               color_mode='grayscale',\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               subset='training')\n",
    "\n",
    "# Conjunto de validación\n",
    "validation_dataset = datagen.flow_from_directory('PetImages/',\n",
    "                                                 target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                 batch_size=100,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 subset='validation')\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(60,60,1)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(60,60,1)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit_generator(training_dataset,\n",
    "                    steps_per_epoch=len(training_dataset),\n",
    "                    epochs = 5,\n",
    "                    validation_steps = len(validation_dataset),\n",
    "                    validation_data = validation_dataset);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(\"PetImages/Cat\")):\n",
    "        label = [0]\n",
    "        path = os.path.join(\"PetImages/Cat\", img)\n",
    "        print(\"Path => \", path)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data\n",
    "\n",
    "a = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import JpegImagePlugin\n",
    "JpegImagePlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
